{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to fetch and compile stonycreek into one excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "import plotly.express as px\n",
    "from datetime import datetime\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from plotly.subplots import make_subplots\n",
    "import requests\n",
    "import io\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox, interact\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import re\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITE_PREFIX = \"Stony\"\n",
    "SITE_NUMBERS = [f\"0{x}\" for x in (1,2,3,4,6,7)] + [\"05-1\", \"05-3\"]\n",
    "SITE_NAMES = [f\"{SITE_PREFIX}{x}\" for x in SITE_NUMBERS]\n",
    "print(SITE_NAMES)\n",
    "BASE_URL = \"https://www.bosl.com.au/IoT/StonyCreek/databases/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_v1 = []\n",
    "all_data_v2 = []\n",
    "for site in SITE_NAMES:\n",
    "    print(f\"Hit: {BASE_URL}{site}.csv, {BASE_URL}{site}_v2.csv\")\n",
    "    all_data_v1.append(pd.read_csv(f\"{BASE_URL}{site}.csv\").dropna(how='all', axis='columns'))\n",
    "    all_data_v2.append(pd.read_csv(f\"{BASE_URL}{site}_v2.csv\").dropna(how='all', axis='columns'))\n",
    "\n",
    "    # Misc data cleaning\n",
    "    # 05-1 has extra row\n",
    "    #if site == f\"{SITE_PREFIX}05-1\":\n",
    "    #    all_data_v1[-1].drop(all_data_v1[-1].tail(1).index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_v1, data_v2 in zip(all_data_v1, all_data_v2):\n",
    "    COLUMN_CONVERSION = {\"DateTime\": \"SiteName\", \"Battery\": \"Velocitybattery\", \"Velocity\": \"VEL\", \"ApproxDepth\": \"DIST\", \"SignalStrength\": \"AMP\",\n",
    "        \"BinaryDepth\": \"WPEAKS\", \"Angle\": \"ANGLE\"}\n",
    "    data_v1.rename(columns=COLUMN_CONVERSION, inplace=True)\n",
    "    data_v2.rename(columns={\"PEAKS\": \"WPEAKS\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_merged_data = []\n",
    "for data_v1, data_v2 in zip(all_data_v1, all_data_v2):\n",
    "    merged_data = pd.concat([data_v1, data_v2])\n",
    "    merged_data.dropna(how='all', subset=merged_data.columns, inplace=True)\n",
    "    merged_data.dropna(axis=1, inplace=True, how='all')\n",
    "    merged_data.dropna(subset=[\"WPEAKS\"], inplace=True)\n",
    "    try:\n",
    "        def extract_peak(row):\n",
    "            peaks = str(row[\"WPEAKS\"]).split(\"|\")\n",
    "            try:\n",
    "                decoded_peaks = [int(x[:3], 16) for x in peaks]\n",
    "            except ValueError:\n",
    "                decoded_peaks = [None] * len(peaks)\n",
    "            finally:\n",
    "                column_names = [f\"DEPTH-{i+1}\" for i in range(len(decoded_peaks))]\n",
    "                return pd.Series(decoded_peaks, index=column_names)\n",
    "        merged_data = pd.concat([merged_data, merged_data.apply(extract_peak, axis=1)], axis=1)\n",
    "        depth_column_names = [col for col in merged_data.columns if 'DEPTH' in col]\n",
    "        \n",
    "        merged_data[depth_column_names] = merged_data[depth_column_names].multiply(np.sin(np.radians(merged_data[\"ANGLE\"])), axis=\"index\")\n",
    "        merged_data[\"SiteName\"] = pd.to_datetime(merged_data[\"SiteName\"], format=\"%d/%m/%y %I:%M:%S %p\")\n",
    "\n",
    "        merged_data.dropna(subset=depth_column_names, axis='rows', inplace=True)\n",
    "\n",
    "        all_merged_data.append(merged_data)\n",
    "        merged_data.dropna(how='all', axis=1, inplace=True)\n",
    "    except ValueError as e:\n",
    "        print(merged_data)\n",
    "        raise e\n",
    "merged_data.dropna(how='all', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative depths are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.loc[merged_data[\"DEPTH-1\"] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for merged_data in all_merged_data:\n",
    "    merged_data.drop(merged_data[merged_data[\"DEPTH-1\"] < 0].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(all_merged_data[0], x='SiteName', y=depth_column_names)\n",
    "f2 = go.FigureWidget(fig)\n",
    "site_id = widgets.IntSlider(value=0, min=0, max=len(SITE_NAMES) - 1, step=1, description='Site index:', continuous_update=False)\n",
    "def response(change):\n",
    "    f2.update_layout(title=f\"Depth data of {SITE_NAMES[site_id.value]}\")\n",
    "    with f2.batch_update():\n",
    "        for idx, col in enumerate(depth_column_names):\n",
    "            f2.data[idx].x = all_merged_data[site_id.value][\"SiteName\"]\n",
    "            f2.data[idx].y = all_merged_data[site_id.value][col]\n",
    "site_id.observe(response, names=\"value\")\n",
    "response(None)\n",
    "widgets.VBox([site_id, f2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_date = np.min(list(x[\"SiteName\"].min() for x in all_merged_data)).date()\n",
    "latest_date = np.max(list(x[\"SiteName\"].max() for x in all_merged_data)).date()\n",
    "\n",
    "url = f\"https://api.melbournewater.com.au/rainfall-river-level/227231A/rain/hourly/range.csv?fromDate={earliest_date}&toDate={latest_date}\"\n",
    "print(url)\n",
    "r = requests.get(url)\n",
    "d = r.headers['content-disposition']\n",
    "rain_filename = re.findall(\"filename=(.+)\", d)[0]\n",
    "rainfall_data = pd.read_csv(io.StringIO(r.content.decode('utf-8'))).dropna(how='all', axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rainfall_data[\"Date/Time\"] = pd.to_datetime(rainfall_data[\"Date/Time\"], format=\"%Y/%m/%d %H:%M:%S\")\n",
    "rainfall_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = rainfall_data.plot(x='Date/Time', y=\"Current rainfall (mm)\", title=f\"Rainfall of {rain_filename}\").update_layout(\n",
    "    xaxis_title=\"Time\", yaxis_title=f\"Rainfall (mm)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Periods in which there is a >1 hr gap is ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_filter = lambda x: x > 1 * 60 * 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "# fig.add_trace(go.Scatter(x=merged_data[\"SiteName\"],\n",
    "#     y=np.where(time_filter(merged_data['SiteName'].diff().dt.seconds), None, merged_data[\"DEPTH-1\"]), \n",
    "#     name=\"Depth\"),\n",
    "#     secondary_y=False)\n",
    "# fig.add_trace(go.Scatter(x=rainfall_data[\"Date/Time\"], y=rainfall_data[\"Current rainfall (mm)\"], name=\"Rainfall\"), secondary_y=True)\n",
    "# fig.update_yaxes(title_text=\"Depth (mm)\", secondary_y=False)\n",
    "# fig.update_yaxes(autorange=\"reversed\", secondary_y=True)\n",
    "# fig.update_yaxes(title_text=\"Rainfall (mm)\", secondary_y=True)\n",
    "# fig.update_xaxes(title_text=\"Time\", tickangle=45, nticks=30)\n",
    "# fig.update_layout(autosize=True, width=1100, height=700, legend=dict(title=\"Lines\"), title=f\"Rainfall vs Depth of {site}\")\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "for site_name, merged_data in zip(SITE_NAMES, all_merged_data):\n",
    "    fig.add_trace(go.Scatter(x=merged_data[\"SiteName\"],\n",
    "    y=np.where(time_filter(merged_data['SiteName'].diff().dt.seconds), None, merged_data[\"DEPTH-1\"]), \n",
    "    name=f\"{site_name}\"),\n",
    "    secondary_y=False)\n",
    "    \n",
    "fig.add_trace(go.Scatter(x=rainfall_data[\"Date/Time\"], y=rainfall_data[\"Current rainfall (mm)\"], name=\"Rainfall\"), secondary_y=True)\n",
    "fig.update_yaxes(title_text=\"Depth (mm)\", secondary_y=False, range = [0, 8000])\n",
    "max_rainfall = rainfall_data[\"Current rainfall (mm)\"].max()\n",
    "fig.update_yaxes(range = [max_rainfall * 4, 0], secondary_y=True)\n",
    "fig.update_yaxes(title_text=\"Rainfall (mm)\", secondary_y=True)\n",
    "fig.update_xaxes(title_text=\"Time\", tickangle=45, nticks=30)\n",
    "fig.update_layout(autosize=False, width=1100, height=700, legend=dict(title=\"Lines\"), title=\"All plots\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = pd.ExcelWriter(f'stony_creek-{datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")}.xlsx', engine='xlsxwriter')\n",
    "for site_name, merged_data in zip(SITE_NAMES, all_merged_data):\n",
    "    merged_data.to_excel(writer, sheet_name=site_name, index=False)\n",
    "rainfall_data.to_excel(writer, sheet_name=f\"{rain_filename[:31]}\", index=False)\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0fc71e8b97747545aede84e60d600f6db536f574f3e4f5399194cbbbcc5912b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
